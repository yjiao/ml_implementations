{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04fc427e",
   "metadata": {},
   "source": [
    "# Relative Positional Encoding + Music Transformer Skewing\n",
    "\n",
    "[Music transformer](https://arxiv.org/pdf/1809.04281.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee3c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import importlib\n",
    "import pickle\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import relative_attention as rpe\n",
    "from src import torch_models as tm\n",
    "from src import data\n",
    "from src import train_utils\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef44858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    importlib.reload(tm)\n",
    "    importlib.reload(rpe)\n",
    "    importlib.reload(data)\n",
    "    importlib.reload(train_utils)\n",
    "    importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e1a52",
   "metadata": {},
   "source": [
    "## BBPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cdaea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_en = 'data/train.en'\n",
    "train_path_de = 'data/train.de'\n",
    "tokenizer_path = \"data/tokenizer-bbpe-joint.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5668bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbpe = data.get_bbpe_tokenizer(tokenizer_path, data_file_list=[train_path_en, train_path_de])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a97af",
   "metadata": {},
   "source": [
    "## model def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cd1bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_modules()\n",
    "max_context = 64\n",
    "max_distance = 32\n",
    "config = rpe.RPEModelConfig(\n",
    "    dim=512,\n",
    "    N=8,\n",
    "    h=8,\n",
    "    V=bbpe.get_vocab_size(),\n",
    "    max_context=max_context,\n",
    "    drop_rate=0.01,\n",
    "    relative=True,\n",
    "    per_layer=True,\n",
    "    use_value_rpe=False,\n",
    "    max_distance=max_distance,\n",
    ")\n",
    "model_krpe_perlayer_skew = rpe.RelativeGPT.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a19a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def print_numel(model, name):\n",
    "    print(f'{name:>30}: {count_params(model):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0e019",
   "metadata": {},
   "source": [
    "Note that the per-layer PE model uses a smaller context and coincidentally ends up with the same number of params as the base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d0915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        per-layer PE with skew: 55,976,243\n"
     ]
    }
   ],
   "source": [
    "print_numel(model_krpe_perlayer_skew, 'per-layer PE with skew')\n",
    "# key-only per-layer RPE: 55,993,139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb05c5",
   "metadata": {},
   "source": [
    "## Data Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b84bf5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train lines: 4468840\n",
      "test lines: 2737\n"
     ]
    }
   ],
   "source": [
    "if 'train_lines' not in locals():\n",
    "    train_lines = sum(1 for line in open(data.TRAIN_PATH_EN, encoding='utf-8'))\n",
    "if 'test_lines' not in locals():\n",
    "    test_lines = sum(1 for line in open(data.TEST_PATH_EN, encoding='utf-8'))\n",
    "print(f'train lines: {train_lines}')\n",
    "print(f'test lines: {test_lines}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f61b4",
   "metadata": {},
   "source": [
    "### training/ data params\n",
    "\n",
    "docs: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e531573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(data)\n",
    "dataset_config = data.DatasetConfig(bbpe, max_context)\n",
    "tok_fn = partial(data.str_to_tok, add_start=False)\n",
    "tok_fn_w_start = partial(data.str_to_tok, add_start=True)\n",
    "\n",
    "def input_fn(en_line, de_line, data_config):\n",
    "    en_input = data.str_to_tok(en_line, data_config, add_start=True)\n",
    "    return [en_input]\n",
    "\n",
    "def target_fn(en_line, de_line, data_config):\n",
    "    return data.str_to_tok(en_line, data_config, add_start=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "179868d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# autoregressive training\n",
    "importlib.reload(data)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset_autoreg = data.WMT2014Mixing(\n",
    "    num_pools=7919,  # pick a prime number\n",
    "    start_line=0,\n",
    "    end_line=train_lines,\n",
    "    process_inputs=input_fn,\n",
    "    process_target=target_fn,\n",
    "    dataset_config=dataset_config,\n",
    "    train=True,\n",
    "    overwrite_de_path=data.TRAIN_PATH_EN,\n",
    ")\n",
    "train_loader_autoreg = torch.utils.data.DataLoader(\n",
    "    train_dataset_autoreg,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataset_autoreg = data.WMT2014Mixing(\n",
    "    num_pools=101,  # pick a prime number\n",
    "    start_line=0,\n",
    "    end_line=test_lines,\n",
    "    process_inputs=input_fn,\n",
    "    process_target=target_fn,\n",
    "    dataset_config=dataset_config,\n",
    "    train=False,\n",
    "    overwrite_de_path=data.TEST_PATH_EN,\n",
    ")\n",
    "test_loader_autoreg = torch.utils.data.DataLoader(\n",
    "    test_dataset_autoreg,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c711f8",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e750a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mingpt_n2_h8_d512_c64', 'autoreg_n2_h8_d512_c64_wproj_xavier', 'autoreg_n2_h8_d512_c64_wproj_mingptinit', 'autoreg_n2_h8_d512_c64_wproj_mingptinit_learnablepe', 'autoreg_n2_h8_d512_c64_wproj_mingptinit_learnablepe_shuffle', 'autoreg_n8_h8_d512_c64_wproj_mingptinit_learnablepe_shuffle', 'res_n8_h8_d256_c64_wproj_mingptinit_learnablepe_shuffle', 'rpe_konly_n8_h8_d512_c64', 'rpe_konly_perlayer_n8_h8_d512_c64', 'autoreg_n8_h8_d512_c64', 'rpe_kv_perlayer_n8_h8_d512_c64', 'rpe_konly_global_n8_h8_d512_c64', 'rpe_konly_perlayer_n8_h8_d512_c64_v2', 'pe_perlayer_n8_h8_d512_c64'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss_histories = dict()\n",
    "with open('./saved_models/loss_histories.pickle', 'rb') as f:\n",
    "    loss_histories = pickle.load(f)\n",
    "with open('./saved_models/loss_histories_bkup.pickle', 'wb') as f:\n",
    "    pickle.dump(loss_histories, f)\n",
    "loss_histories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e720665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 157/69826 [00:57<39:48:34,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       10048: training loss 5.727814674377441, test loss 5.896206356758295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 313/69826 [01:56<40:01:51,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       20032: training loss 4.889087677001953, test loss 5.16634096101273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 469/69826 [02:53<42:35:44,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       30016: training loss 4.718327522277832, test loss 4.820888541465582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 625/69826 [03:51<45:39:39,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       40000: training loss 4.295259475708008, test loss 4.646061243012894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 782/69826 [04:48<40:12:43,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       50048: training loss 4.27577018737793, test loss 4.528921471085659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 938/69826 [05:45<39:53:40,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       60032: training loss 4.211437702178955, test loss 4.431851819504139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1094/69826 [06:41<40:12:02,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       70016: training loss 4.144989967346191, test loss 4.36605135230131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1250/69826 [07:38<39:42:24,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       80000: training loss 4.109028339385986, test loss 4.308094468227653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1407/69826 [08:35<39:47:03,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       90048: training loss 4.0265045166015625, test loss 4.271093945170557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1563/69826 [09:32<39:54:30,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      100032: training loss 3.964172601699829, test loss 4.230042945506961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1719/69826 [10:28<39:27:49,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      110016: training loss 3.752964973449707, test loss 4.200234828993332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1875/69826 [11:24<39:07:17,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      120000: training loss 4.05147123336792, test loss 4.161135950753855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2032/69826 [12:21<38:49:57,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      130048: training loss 3.8165464401245117, test loss 4.13623188262762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2188/69826 [13:18<38:44:28,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      140032: training loss 3.7234063148498535, test loss 4.123438918313314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2344/69826 [14:14<38:40:27,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      150016: training loss 3.584164619445801, test loss 4.094466525454854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2500/69826 [15:10<38:47:18,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      160000: training loss 3.763683319091797, test loss 4.071765766587368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2657/69826 [16:08<39:16:57,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      170048: training loss 3.7666256427764893, test loss 4.0531638001286705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2813/69826 [17:06<44:32:37,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      180032: training loss 3.529785394668579, test loss 4.048829710760782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2969/69826 [18:02<38:50:03,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      190016: training loss 3.569786548614502, test loss 4.0149981143862705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3125/69826 [18:59<38:22:14,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      200000: training loss 3.3961784839630127, test loss 3.993880560231763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3282/69826 [19:55<38:50:39,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      210048: training loss 3.5521864891052246, test loss 3.9920277207396753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3438/69826 [20:52<38:43:03,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      220032: training loss 3.621865749359131, test loss 3.9685768304869184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3594/69826 [21:50<39:43:32,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      230016: training loss 3.5443243980407715, test loss 3.9702996819518335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3750/69826 [22:48<39:50:01,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      240000: training loss 3.5074405670166016, test loss 3.944537101789962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3907/69826 [23:46<39:32:42,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      250048: training loss 3.446305990219116, test loss 3.9544016705002893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 4063/69826 [24:43<39:00:02,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      260032: training loss 3.361663341522217, test loss 3.931640026181243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 4219/69826 [25:41<39:20:08,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      270016: training loss 3.308894395828247, test loss 3.915595376214316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 4375/69826 [26:40<44:17:31,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      280000: training loss 3.496526002883911, test loss 3.9075615960498187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 4532/69826 [27:39<42:07:56,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      290048: training loss 3.551832675933838, test loss 3.8969768867936243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4688/69826 [28:37<38:51:11,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      300032: training loss 3.3504743576049805, test loss 3.899039007896601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4844/69826 [29:34<39:12:33,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      310016: training loss 3.2674849033355713, test loss 3.880716041077015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5000/69826 [30:32<38:36:24,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      320000: training loss 3.357046604156494, test loss 3.872518079225407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5157/69826 [31:30<39:01:29,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      330048: training loss 3.4817087650299072, test loss 3.8725953434788902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5313/69826 [32:30<38:38:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      340032: training loss 3.6746575832366943, test loss 3.871489086816477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5469/69826 [33:27<39:05:15,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      350016: training loss 3.4619412422180176, test loss 3.8543276398680932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5625/69826 [34:25<39:00:42,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      360000: training loss 3.406461238861084, test loss 3.8598134406777316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5782/69826 [35:24<38:54:38,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      370048: training loss 3.237543821334839, test loss 3.840041842571525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 5938/69826 [36:21<38:45:59,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      380032: training loss 3.347060441970825, test loss 3.830158932264461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 6094/69826 [37:19<38:41:08,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      390016: training loss 3.5753378868103027, test loss 3.8205970997034115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6250/69826 [38:18<39:00:11,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      400000: training loss 3.2552709579467773, test loss 3.8288023693617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6407/69826 [39:15<38:47:28,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      410048: training loss 3.411587715148926, test loss 3.8180083452269087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6563/69826 [40:14<38:07:17,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      420032: training loss 3.4034316539764404, test loss 3.8025571412818375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 6719/69826 [41:12<37:51:28,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      430016: training loss 3.4352927207946777, test loss 3.784055332804835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 6875/69826 [42:09<37:37:01,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      440000: training loss 3.238415241241455, test loss 3.790207624435425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 7032/69826 [43:07<37:37:23,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      450048: training loss 3.299973487854004, test loss 3.7949458887410716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 7188/69826 [44:04<37:20:56,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      460032: training loss 3.2510037422180176, test loss 3.782296846079272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7344/69826 [45:02<36:38:39,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      470016: training loss 3.3174450397491455, test loss 3.781565266986226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7500/69826 [46:00<41:54:32,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      480000: training loss 3.310204267501831, test loss 3.763070267300273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7657/69826 [47:00<41:36:54,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      490048: training loss 3.4348809719085693, test loss 3.779272667197294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7813/69826 [47:57<36:02:37,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      500032: training loss 3.2065110206604004, test loss 3.770979598511097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 7969/69826 [48:55<36:20:33,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      510016: training loss 3.1100056171417236, test loss 3.7583066640898237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 8125/69826 [49:53<36:40:38,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      520000: training loss 3.2383780479431152, test loss 3.7367810981218206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 8282/69826 [50:50<37:13:47,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      530048: training loss 3.227954626083374, test loss 3.7346118106398474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 8438/69826 [51:48<36:29:22,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      540032: training loss 3.2283356189727783, test loss 3.7395847786304564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 8594/69826 [52:45<36:12:47,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      550016: training loss 3.2298669815063477, test loss 3.7462983796762868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 8750/69826 [53:42<36:47:21,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      560000: training loss 3.254549503326416, test loss 3.7384089037429455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 8907/69826 [54:38<35:12:42,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      570048: training loss 3.3711254596710205, test loss 3.725150418836017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 9063/69826 [55:35<35:21:07,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      580032: training loss 3.117609977722168, test loss 3.7328909607820733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 9219/69826 [56:31<35:01:36,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      590016: training loss 3.262134313583374, test loss 3.718311847642411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 9375/69826 [57:29<34:59:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      600000: training loss 3.0821824073791504, test loss 3.7144704197728355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 9532/69826 [58:25<34:41:31,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      610048: training loss 3.154158592224121, test loss 3.7206767991531726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 9688/69826 [59:22<39:55:42,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      620032: training loss 3.023805618286133, test loss 3.7009070141370906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 9844/69826 [1:00:19<34:44:08,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      630016: training loss 3.2354729175567627, test loss 3.7094165558038754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 10000/69826 [1:01:16<34:41:14,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      640000: training loss 3.3923141956329346, test loss 3.7106389722158744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 10157/69826 [1:02:14<40:10:50,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      650048: training loss 3.198352098464966, test loss 3.69671256597652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 10313/69826 [1:03:11<34:38:23,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      660032: training loss 3.236093521118164, test loss 3.7048908222553343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 10469/69826 [1:04:07<34:34:59,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      670016: training loss 3.0992038249969482, test loss 3.6983783577763756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 10625/69826 [1:05:04<34:08:44,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      680000: training loss 3.142428398132324, test loss 3.691638148108194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 10782/69826 [1:06:00<34:25:38,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      690048: training loss 3.2057809829711914, test loss 3.696442825849666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 10938/69826 [1:06:57<34:15:24,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      700032: training loss 3.029517412185669, test loss 3.6899885854055716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 11094/69826 [1:07:53<34:10:44,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      710016: training loss 3.2431180477142334, test loss 3.675647779952648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 11250/69826 [1:08:50<34:27:46,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      720000: training loss 3.020259380340576, test loss 3.6816304118134253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 11407/69826 [1:09:47<33:56:51,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      730048: training loss 3.0833473205566406, test loss 3.669387695401214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 11563/69826 [1:10:43<33:36:59,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      740032: training loss 3.1996536254882812, test loss 3.656350900960523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 11719/69826 [1:11:40<34:32:25,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      750016: training loss 3.091733932495117, test loss 3.6585217409355697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 11875/69826 [1:12:37<34:12:54,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      760000: training loss 3.05147123336792, test loss 3.6751825975817303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 12032/69826 [1:13:35<34:25:03,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      770048: training loss 3.3447535037994385, test loss 3.666246214578318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 12188/69826 [1:14:32<33:49:34,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      780032: training loss 3.2007012367248535, test loss 3.6486270372257676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 12344/69826 [1:15:29<33:44:04,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      790016: training loss 3.210629940032959, test loss 3.644316834072734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 12500/69826 [1:16:26<33:46:59,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      800000: training loss 3.326294422149658, test loss 3.6488531301187916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 12657/69826 [1:17:23<33:30:24,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      810048: training loss 3.105229139328003, test loss 3.645067259322765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 12813/69826 [1:18:20<35:31:16,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      820032: training loss 3.2118897438049316, test loss 3.638710321382035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 12969/69826 [1:19:17<33:32:31,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      830016: training loss 3.0760037899017334, test loss 3.6386011256728064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 13125/69826 [1:20:14<33:38:30,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      840000: training loss 3.2559902667999268, test loss 3.636581359907638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 13282/69826 [1:21:14<33:34:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      850048: training loss 3.292325019836426, test loss 3.6331884472869165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 13438/69826 [1:22:11<33:36:23,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      860032: training loss 3.0151126384735107, test loss 3.636677769727485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 13594/69826 [1:23:08<33:43:17,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      870016: training loss 3.202970027923584, test loss 3.6428061529647473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 13750/69826 [1:24:07<33:18:38,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      880000: training loss 3.0397579669952393, test loss 3.629121835841689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 13907/69826 [1:25:05<32:49:08,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      890048: training loss 3.041015863418579, test loss 3.6406212684720063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 14063/69826 [1:26:03<37:23:56,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      900032: training loss 3.106233835220337, test loss 3.6337115598279377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 14219/69826 [1:27:01<33:09:39,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      910016: training loss 3.1515049934387207, test loss 3.627785849016766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 14375/69826 [1:27:58<33:25:09,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      920000: training loss 3.2223525047302246, test loss 3.62369135368702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 14532/69826 [1:29:00<37:10:35,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      930048: training loss 2.969034433364868, test loss 3.619038376697274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 14688/69826 [1:30:01<37:20:41,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      940032: training loss 3.2577462196350098, test loss 3.6231988696164863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 14844/69826 [1:31:00<36:57:52,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      950016: training loss 3.070162773132324, test loss 3.6119729474533435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 15000/69826 [1:31:58<32:27:55,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      960000: training loss 3.28588604927063, test loss 3.6100777193557385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 15157/69826 [1:32:56<32:36:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      970048: training loss 2.9875476360321045, test loss 3.6130986380022625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 15313/69826 [1:33:53<32:26:36,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      980032: training loss 3.116720199584961, test loss 3.5995937835338503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 15469/69826 [1:34:51<32:26:51,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      990016: training loss 3.0222091674804688, test loss 3.60655907142994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 15625/69826 [1:35:48<32:16:50,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1000000: training loss 3.165846109390259, test loss 3.602336428886236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 15782/69826 [1:36:46<32:19:55,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1010048: training loss 2.91562819480896, test loss 3.603956616202066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 15938/69826 [1:37:42<31:45:24,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1020032: training loss 3.097519874572754, test loss 3.6074994719305704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 16094/69826 [1:38:39<31:03:21,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1030016: training loss 3.0753912925720215, test loss 3.589092648306558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 16250/69826 [1:39:37<32:17:17,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1040000: training loss 3.2531321048736572, test loss 3.594165020210798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 16407/69826 [1:40:34<31:07:23,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1050048: training loss 3.089094400405884, test loss 3.6005188531653824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 16563/69826 [1:41:31<31:46:01,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1060032: training loss 3.1567060947418213, test loss 3.579771174940952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 16719/69826 [1:42:30<35:26:05,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1070016: training loss 3.117192268371582, test loss 3.5848654259082884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 16875/69826 [1:43:29<31:27:21,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1080000: training loss 3.180440664291382, test loss 3.5893830365912858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 17032/69826 [1:44:27<33:35:28,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1090048: training loss 2.833850860595703, test loss 3.5852302007896957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 17188/69826 [1:45:28<35:08:58,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1100032: training loss 3.0601389408111572, test loss 3.583384170088657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 17344/69826 [1:46:26<31:18:28,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1110016: training loss 3.0571582317352295, test loss 3.591637927432393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 17500/69826 [1:47:25<31:08:47,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1120000: training loss 3.165274143218994, test loss 3.5747150931247447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 17657/69826 [1:48:23<31:11:59,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1130048: training loss 2.9862616062164307, test loss 3.5915015797282375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 17813/69826 [1:49:21<30:57:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1140032: training loss 3.210970401763916, test loss 3.581633346025334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 17969/69826 [1:50:18<30:54:30,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1150016: training loss 3.0123543739318848, test loss 3.5742706919825356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 18125/69826 [1:51:15<30:49:46,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1160000: training loss 3.09464430809021, test loss 3.564749318499898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 18282/69826 [1:52:13<30:29:52,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1170048: training loss 3.0571813583374023, test loss 3.5746911736421807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 18438/69826 [1:53:10<30:31:03,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1180032: training loss 3.107572078704834, test loss 3.568459943283436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 18594/69826 [1:54:07<30:09:29,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1190016: training loss 2.8714733123779297, test loss 3.564175156659858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 18750/69826 [1:55:05<30:01:29,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1200000: training loss 2.8364064693450928, test loss 3.5631130906038506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 18907/69826 [1:56:02<29:41:09,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1210048: training loss 3.0069730281829834, test loss 3.550557175347971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 19063/69826 [1:56:59<29:54:29,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1220032: training loss 2.8796472549438477, test loss 3.554625289384709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 19219/69826 [1:57:56<29:45:50,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1230016: training loss 3.0887374877929688, test loss 3.56419477906338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 19375/69826 [1:58:53<29:24:43,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1240000: training loss 3.1435227394104004, test loss 3.5551570071730505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 19532/69826 [1:59:50<29:23:01,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1250048: training loss 3.0351555347442627, test loss 3.555771267691324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 19688/69826 [2:00:47<29:11:48,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1260032: training loss 2.848238945007324, test loss 3.5399957645771116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 19844/69826 [2:01:44<33:14:29,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1270016: training loss 2.991647958755493, test loss 3.554459854613903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 20000/69826 [2:02:41<29:11:32,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1280000: training loss 2.8801372051239014, test loss 3.565996208856272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 20157/69826 [2:03:38<28:55:32,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1290048: training loss 2.985764741897583, test loss 3.5409864436748415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 20313/69826 [2:04:35<28:58:23,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1300032: training loss 3.1925487518310547, test loss 3.5537748004114906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 20469/69826 [2:05:32<28:48:47,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1310016: training loss 2.8856496810913086, test loss 3.5491892237995946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 20625/69826 [2:06:29<28:30:23,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1320000: training loss 3.0611183643341064, test loss 3.5374374167863714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 20782/69826 [2:07:26<28:40:36,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1330048: training loss 2.9973795413970947, test loss 3.5377271508061607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 20938/69826 [2:08:23<28:31:05,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1340032: training loss 3.1615068912506104, test loss 3.551530350086301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 21094/69826 [2:09:20<30:38:53,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1350016: training loss 3.343226909637451, test loss 3.5314825745516045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 21250/69826 [2:10:17<28:22:51,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1360000: training loss 3.234950304031372, test loss 3.539492407510447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 21407/69826 [2:11:15<28:46:30,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1370048: training loss 3.0336451530456543, test loss 3.536765464516573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 21563/69826 [2:12:12<28:33:48,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1380032: training loss 2.851644992828369, test loss 3.5282099468763484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 21719/69826 [2:13:09<28:21:54,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1390016: training loss 2.904101610183716, test loss 3.528614509937375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 21875/69826 [2:14:06<28:28:36,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1400000: training loss 2.9828481674194336, test loss 3.5281752763792524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 22032/69826 [2:15:03<28:11:09,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1410048: training loss 2.8735907077789307, test loss 3.517804744631745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 22188/69826 [2:16:00<28:13:24,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1420032: training loss 2.9713780879974365, test loss 3.5265388156092445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 22344/69826 [2:16:58<27:41:09,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1430016: training loss 3.250516176223755, test loss 3.5277894264043765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 22500/69826 [2:17:55<28:00:56,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1440000: training loss 3.0423974990844727, test loss 3.512719841890557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 22657/69826 [2:18:53<27:47:23,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1450048: training loss 3.0112903118133545, test loss 3.525775804076084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 22813/69826 [2:19:49<27:28:51,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1460032: training loss 3.21117901802063, test loss 3.5151299044143323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 22969/69826 [2:20:47<31:20:19,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1470016: training loss 3.075620174407959, test loss 3.5253988864809966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 23125/69826 [2:21:44<27:16:02,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1480000: training loss 2.9567596912384033, test loss 3.5097393767778264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 23282/69826 [2:22:42<27:06:37,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1490048: training loss 3.1287057399749756, test loss 3.5219195942546047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 23438/69826 [2:23:40<31:03:19,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1500032: training loss 2.849025011062622, test loss 3.5137363977210465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 23594/69826 [2:24:38<26:52:53,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1510016: training loss 3.074655532836914, test loss 3.5287781870642374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 23750/69826 [2:25:36<27:10:59,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1520000: training loss 2.9198551177978516, test loss 3.5198483245317327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 23907/69826 [2:26:33<26:49:30,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1530048: training loss 3.0690343379974365, test loss 3.5147151836129122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 24063/69826 [2:27:31<30:45:32,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1540032: training loss 2.911492347717285, test loss 3.5190354557924493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 24219/69826 [2:28:27<26:42:27,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1550016: training loss 3.1759586334228516, test loss 3.5061101858005967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 24375/69826 [2:29:25<26:39:30,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1560000: training loss 2.9095044136047363, test loss 3.505231679872025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 24532/69826 [2:30:22<26:33:44,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1570048: training loss 2.966357946395874, test loss 3.498887383660605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 24688/69826 [2:31:19<26:25:50,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1580032: training loss 3.0208382606506348, test loss 3.514489445575448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 24844/69826 [2:32:16<26:29:29,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1590016: training loss 3.0071446895599365, test loss 3.511962275172389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 25000/69826 [2:33:13<26:04:53,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1600000: training loss 3.089186191558838, test loss 3.510234084240226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 25157/69826 [2:34:10<26:03:21,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1610048: training loss 2.848262310028076, test loss 3.511758704518163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 25313/69826 [2:35:07<27:40:43,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1620032: training loss 3.1015820503234863, test loss 3.506246566772461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 25469/69826 [2:36:04<25:53:24,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1630016: training loss 2.9008114337921143, test loss 3.4960116951964624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 25625/69826 [2:37:01<26:08:24,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1640000: training loss 2.8965611457824707, test loss 3.492125688597213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 25782/69826 [2:37:58<25:59:03,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1650048: training loss 2.9945285320281982, test loss 3.5074008398277816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 25938/69826 [2:38:55<25:36:58,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1660032: training loss 2.9719042778015137, test loss 3.50124808244927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 26094/69826 [2:39:52<25:33:24,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1670016: training loss 2.7928593158721924, test loss 3.5050098674241887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 26250/69826 [2:40:49<25:15:36,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1680000: training loss 3.042524576187134, test loss 3.498733681301738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 26407/69826 [2:41:46<25:31:31,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1690048: training loss 2.9889180660247803, test loss 3.4959330392438313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 26563/69826 [2:42:42<25:17:42,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1700032: training loss 3.280315399169922, test loss 3.4993042890415635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 26719/69826 [2:43:39<25:09:18,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1710016: training loss 3.0322282314300537, test loss 3.488003514533819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 26875/69826 [2:44:36<25:07:22,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1720000: training loss 2.9062435626983643, test loss 3.495237161946851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 27032/69826 [2:45:33<24:48:23,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1730048: training loss 3.104832649230957, test loss 3.4933061710623807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 27188/69826 [2:46:30<24:56:21,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1740032: training loss 2.59812331199646, test loss 3.486130409462507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 27344/69826 [2:47:26<24:46:13,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1750016: training loss 2.93906569480896, test loss 3.485006254772807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 27500/69826 [2:48:23<24:49:53,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1760000: training loss 3.1815741062164307, test loss 3.500122613685076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 27657/69826 [2:49:21<27:57:09,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1770048: training loss 2.785553455352783, test loss 3.487586880839148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 27813/69826 [2:50:19<24:59:46,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1780032: training loss 2.9290807247161865, test loss 3.4925381194713503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 27969/69826 [2:51:16<27:50:28,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1790016: training loss 3.009098529815674, test loss 3.4904595641202705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 28125/69826 [2:52:14<24:07:58,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1800000: training loss 2.9928343296051025, test loss 3.4903749310693075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 28282/69826 [2:53:11<24:04:38,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1810048: training loss 2.9591104984283447, test loss 3.4768937798433526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 28438/69826 [2:54:09<27:25:41,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1820032: training loss 3.0138304233551025, test loss 3.4791251005128374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 28594/69826 [2:55:06<24:22:13,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1830016: training loss 2.971219778060913, test loss 3.4614156068757524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 28750/69826 [2:56:02<23:59:29,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1840000: training loss 2.9898858070373535, test loss 3.481996924378151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 28907/69826 [2:57:00<23:58:01,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1850048: training loss 2.907649278640747, test loss 3.468907267548317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 29063/69826 [2:57:58<23:45:36,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1860032: training loss 2.939354419708252, test loss 3.477207206016363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 29219/69826 [2:58:54<23:34:43,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1870016: training loss 3.0360488891601562, test loss 3.4835034082102223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 29375/69826 [2:59:53<29:22:23,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1880000: training loss 3.003568410873413, test loss 3.4829763090887735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 29532/69826 [3:00:51<23:36:55,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1890048: training loss 3.0717263221740723, test loss 3.467265544935714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 29688/69826 [3:01:48<23:16:50,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1900032: training loss 2.9853055477142334, test loss 3.470308597697768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 29844/69826 [3:02:45<23:20:27,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1910016: training loss 3.081301689147949, test loss 3.4900315306907475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 30000/69826 [3:03:42<23:17:14,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1920000: training loss 2.9257254600524902, test loss 3.483023920724558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 30157/69826 [3:04:39<23:14:35,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1930048: training loss 3.0543367862701416, test loss 3.4692241868307425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 30313/69826 [3:05:36<23:14:18,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1940032: training loss 2.808626413345337, test loss 3.466856779054154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 30469/69826 [3:06:33<23:01:44,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1950016: training loss 2.7026031017303467, test loss 3.4719986305680384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 30625/69826 [3:07:29<22:34:44,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1960000: training loss 2.8770251274108887, test loss 3.467091260954391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 30782/69826 [3:08:26<22:32:12,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1970048: training loss 2.9353814125061035, test loss 3.4669223386187884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 30938/69826 [3:09:24<25:47:38,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1980032: training loss 2.9261131286621094, test loss 3.4670879120050473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 31094/69826 [3:10:21<22:27:43,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1990016: training loss 2.678117513656616, test loss 3.455125464949497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 31250/69826 [3:11:18<22:36:16,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2000000: training loss 2.967862844467163, test loss 3.456587702728981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 31407/69826 [3:12:14<22:24:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2010048: training loss 3.0293405055999756, test loss 3.4565549229466637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 31563/69826 [3:13:11<22:23:57,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2020032: training loss 2.7738521099090576, test loss 3.463520371636679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 31719/69826 [3:14:08<22:25:10,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2030016: training loss 2.8925201892852783, test loss 3.455721195354018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 31875/69826 [3:15:06<22:14:05,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2040000: training loss 2.7538907527923584, test loss 3.4560228946597076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 32032/69826 [3:16:03<22:26:16,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2050048: training loss 2.990262746810913, test loss 3.455219961876093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 32188/69826 [3:17:00<22:00:50,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2060032: training loss 3.1286427974700928, test loss 3.457535361134729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 32344/69826 [3:17:57<21:56:02,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2070016: training loss 2.9665093421936035, test loss 3.455969056417776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 32500/69826 [3:18:56<21:57:11,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2080000: training loss 2.7996788024902344, test loss 3.457575188126675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 32657/69826 [3:19:54<21:56:27,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2090048: training loss 2.9790399074554443, test loss 3.4545829684235327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 32813/69826 [3:20:51<21:47:57,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2100032: training loss 2.8564646244049072, test loss 3.451906365017558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 32969/69826 [3:21:49<21:36:51,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2110016: training loss 2.99399471282959, test loss 3.456798037817312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 33125/69826 [3:22:46<21:14:11,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2120000: training loss 2.9590859413146973, test loss 3.4426395948543105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 33282/69826 [3:23:43<21:10:26,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2130048: training loss 3.191654682159424, test loss 3.460595175277355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 33438/69826 [3:24:39<21:03:30,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2140032: training loss 2.9238181114196777, test loss 3.4636931862942006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 33594/69826 [3:25:36<22:13:51,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2150016: training loss 2.8300158977508545, test loss 3.4598058378973673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 33750/69826 [3:26:33<20:52:05,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2160000: training loss 2.9301798343658447, test loss 3.4617306132649266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 33907/69826 [3:27:30<20:52:51,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2170048: training loss 3.070007801055908, test loss 3.4539977561595827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 34063/69826 [3:28:28<20:58:40,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2180032: training loss 2.768768548965454, test loss 3.4654402400172035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 34219/69826 [3:29:24<20:31:52,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2190016: training loss 2.979872465133667, test loss 3.45255623307339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 34375/69826 [3:30:22<20:59:21,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2200000: training loss 2.8745009899139404, test loss 3.445935604184173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 34532/69826 [3:31:20<20:33:54,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2210048: training loss 2.852998733520508, test loss 3.445385672325312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 34688/69826 [3:32:18<20:53:26,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2220032: training loss 2.892712354660034, test loss 3.439631168232408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 34844/69826 [3:33:15<20:25:13,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2230016: training loss 2.999821186065674, test loss 3.4419986647228864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 35000/69826 [3:34:12<20:13:17,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2240000: training loss 2.9175498485565186, test loss 3.4394516002300173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 35157/69826 [3:35:08<20:07:49,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2250048: training loss 2.8411338329315186, test loss 3.4376434559045834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 35313/69826 [3:36:05<20:12:39,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2260032: training loss 3.0464446544647217, test loss 3.4335593456445737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 35469/69826 [3:37:03<19:58:36,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2270016: training loss 2.8881237506866455, test loss 3.431694424429605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 35625/69826 [3:38:00<19:52:50,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2280000: training loss 2.7558276653289795, test loss 3.4422859258429948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 35782/69826 [3:38:58<19:59:32,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2290048: training loss 2.999652147293091, test loss 3.435403868209484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 35938/69826 [3:39:56<22:24:42,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2300032: training loss 2.7998881340026855, test loss 3.4394873741061187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 36094/69826 [3:40:53<20:13:28,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2310016: training loss 2.996596574783325, test loss 3.432585411293562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 36250/69826 [3:41:50<19:29:49,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2320000: training loss 2.87957501411438, test loss 3.429750592209572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 36407/69826 [3:42:47<19:13:21,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2330048: training loss 2.705270290374756, test loss 3.4409604737924977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 36563/69826 [3:43:44<19:21:47,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2340032: training loss 2.810542106628418, test loss 3.4299415821252865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 36719/69826 [3:44:40<19:19:21,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2350016: training loss 2.881161689758301, test loss 3.4342651588972224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 36875/69826 [3:45:37<19:01:19,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2360000: training loss 2.9252424240112305, test loss 3.4278986897579458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 37032/69826 [3:46:34<18:55:03,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2370048: training loss 2.7858104705810547, test loss 3.426235792248748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 37188/69826 [3:47:30<18:46:52,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2380032: training loss 2.872204303741455, test loss 3.4332173535990163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 37344/69826 [3:48:26<18:47:11,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2390016: training loss 2.704819679260254, test loss 3.428864517877268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 37500/69826 [3:49:22<18:37:53,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2400000: training loss 2.9307703971862793, test loss 3.4278615186380788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 37657/69826 [3:50:20<19:46:16,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2410048: training loss 2.947007656097412, test loss 3.42999344093855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 37813/69826 [3:51:16<18:35:58,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2420032: training loss 2.895498514175415, test loss 3.430518438649732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 37969/69826 [3:52:13<18:26:51,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2430016: training loss 2.8167169094085693, test loss 3.425064203351043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 38125/69826 [3:53:09<18:20:46,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2440000: training loss 2.7548043727874756, test loss 3.4362825903781626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 38282/69826 [3:54:08<21:03:53,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2450048: training loss 2.713181972503662, test loss 3.428740922794786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 38438/69826 [3:55:05<18:14:57,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2460032: training loss 3.0611135959625244, test loss 3.4241509548453397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 38594/69826 [3:56:02<18:10:50,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2470016: training loss 3.033036708831787, test loss 3.4231434422870013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 38750/69826 [3:56:59<18:23:58,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2480000: training loss 3.0016767978668213, test loss 3.4251840558162954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 38907/69826 [3:57:56<18:16:43,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2490048: training loss 2.8886961936950684, test loss 3.432860014050506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 39063/69826 [3:58:54<18:13:28,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2500032: training loss 2.8923778533935547, test loss 3.4263970907344374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 39219/69826 [3:59:51<18:20:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2510016: training loss 2.692203998565674, test loss 3.426950299462607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 39375/69826 [4:00:48<17:59:48,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2520000: training loss 2.8508994579315186, test loss 3.425994324129681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 39532/69826 [4:01:45<17:53:24,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2530048: training loss 2.9777398109436035, test loss 3.414623121882594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 39688/69826 [4:02:42<17:25:40,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2540032: training loss 2.9325132369995117, test loss 3.4223101139068604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 39844/69826 [4:03:38<17:25:18,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2550016: training loss 2.8802731037139893, test loss 3.427814993747445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 40000/69826 [4:04:35<17:15:41,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2560000: training loss 2.790881633758545, test loss 3.4306086606757584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 40157/69826 [4:05:32<17:09:53,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2570048: training loss 2.7752699851989746, test loss 3.4196137383926746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 40313/69826 [4:06:29<17:12:24,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2580032: training loss 2.8919599056243896, test loss 3.4200854246006456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 40469/69826 [4:07:26<17:12:18,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2590016: training loss 2.79630184173584, test loss 3.419745500697646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 40625/69826 [4:08:22<17:10:40,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2600000: training loss 2.83188533782959, test loss 3.4183403724847836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 40782/69826 [4:09:21<19:25:16,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2610048: training loss 2.9322383403778076, test loss 3.421412567759669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 40938/69826 [4:10:18<16:49:39,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2620032: training loss 2.8270256519317627, test loss 3.418810955313749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 41094/69826 [4:11:15<16:37:55,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2630016: training loss 2.8538081645965576, test loss 3.4145207127859427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 41250/69826 [4:12:12<16:41:46,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2640000: training loss 2.9365131855010986, test loss 3.4071616405664487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 41407/69826 [4:13:09<16:43:35,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2650048: training loss 2.881063461303711, test loss 3.4147414551224817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 41563/69826 [4:14:05<16:34:47,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2660032: training loss 2.97584867477417, test loss 3.405200952707335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 41719/69826 [4:15:03<18:39:30,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2670016: training loss 2.860342025756836, test loss 3.420117361601009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 41875/69826 [4:16:01<17:15:32,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2680000: training loss 3.1960718631744385, test loss 3.4034001383670542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 42032/69826 [4:16:58<16:15:35,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2690048: training loss 2.771479606628418, test loss 3.4068223265714423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 42188/69826 [4:17:56<18:24:01,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2700032: training loss 2.7940242290496826, test loss 3.4077927733576576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 42344/69826 [4:18:54<18:18:33,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2710016: training loss 2.9397525787353516, test loss 3.4029116907785104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 42500/69826 [4:19:53<18:18:55,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2720000: training loss 2.9960081577301025, test loss 3.406217015066812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 42657/69826 [4:20:51<16:00:56,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2730048: training loss 2.856689691543579, test loss 3.399883591851523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 42813/69826 [4:21:48<15:59:20,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2740032: training loss 2.9828598499298096, test loss 3.3887136315190514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 42969/69826 [4:22:46<17:47:36,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2750016: training loss 2.949659824371338, test loss 3.401181237642155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 43125/69826 [4:23:42<15:32:09,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2760000: training loss 2.715517520904541, test loss 3.4024687090585397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 43282/69826 [4:24:40<15:23:53,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2770048: training loss 2.946333408355713, test loss 3.4018131466799004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 43438/69826 [4:25:36<15:12:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2780032: training loss 2.9458210468292236, test loss 3.396612660829411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 43594/69826 [4:26:32<15:08:56,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2790016: training loss 2.889479398727417, test loss 3.404659027277037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 43750/69826 [4:27:29<15:03:31,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2800000: training loss 2.864678382873535, test loss 3.3909912331159724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 43907/69826 [4:28:26<15:04:02,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2810048: training loss 2.7973825931549072, test loss 3.3986586859059886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 44063/69826 [4:29:23<15:03:52,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2820032: training loss 2.7922000885009766, test loss 3.39825206579164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 44219/69826 [4:30:19<14:47:25,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2830016: training loss 2.9589507579803467, test loss 3.3845080830330074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 44375/69826 [4:31:16<14:56:14,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2840000: training loss 2.866384506225586, test loss 3.401828704878341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 44532/69826 [4:32:13<14:44:25,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2850048: training loss 2.8938186168670654, test loss 3.3964795456376184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 44688/69826 [4:33:10<14:37:36,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2860032: training loss 2.7801671028137207, test loss 3.3972750486329546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 44844/69826 [4:34:06<14:36:50,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2870016: training loss 2.882258415222168, test loss 3.3913471144299177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 45000/69826 [4:35:03<14:27:02,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2880000: training loss 2.75661039352417, test loss 3.394278598386188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 45157/69826 [4:36:00<14:31:45,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2890048: training loss 2.7498350143432617, test loss 3.398509097653766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 45313/69826 [4:36:56<14:15:04,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2900032: training loss 2.8393754959106445, test loss 3.393992695697518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 45469/69826 [4:37:53<14:09:28,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2910016: training loss 2.8232057094573975, test loss 3.400644673857578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 45625/69826 [4:38:49<14:10:06,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2920000: training loss 2.7281062602996826, test loss 3.3998798381450563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 45782/69826 [4:39:46<14:00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2930048: training loss 2.68932843208313, test loss 3.388090455254843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 45938/69826 [4:40:43<14:46:42,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2940032: training loss 2.783942699432373, test loss 3.397472298422525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 46094/69826 [4:41:40<13:51:41,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2950016: training loss 2.7966911792755127, test loss 3.40059550972872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 46250/69826 [4:42:36<13:44:36,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2960000: training loss 2.668807029724121, test loss 3.4040630695431733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 46407/69826 [4:43:33<13:24:22,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2970048: training loss 2.9445018768310547, test loss 3.3939888865448706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 46563/69826 [4:44:29<13:22:06,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2980032: training loss 2.88435959815979, test loss 3.3924636230912317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 46719/69826 [4:45:25<13:17:42,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2990016: training loss 2.7665822505950928, test loss 3.4040630917216457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 46875/69826 [4:46:21<13:11:24,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3000000: training loss 2.7269375324249268, test loss 3.407163281773412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 47032/69826 [4:47:17<13:14:48,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3010048: training loss 2.9919402599334717, test loss 3.3886165175327037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 47188/69826 [4:48:14<13:03:54,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3020032: training loss 2.734746217727661, test loss 3.3867590593737225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 47344/69826 [4:49:10<13:00:38,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3030016: training loss 2.8463523387908936, test loss 3.387226842170538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 47500/69826 [4:50:06<12:57:46,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3040000: training loss 2.877002000808716, test loss 3.3985792204391125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 47657/69826 [4:51:03<12:58:27,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3050048: training loss 2.7811641693115234, test loss 3.3849050166995025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 47813/69826 [4:51:59<12:46:37,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3060032: training loss 3.0293805599212646, test loss 3.3843301895052886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 47969/69826 [4:52:55<12:35:38,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3070016: training loss 2.8483920097351074, test loss 3.3889172908871674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 48125/69826 [4:53:52<12:33:57,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3080000: training loss 2.8217930793762207, test loss 3.3879451030908627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 48282/69826 [4:54:48<12:31:42,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3090048: training loss 2.754291534423828, test loss 3.384482461352681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 48438/69826 [4:55:45<12:19:34,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3100032: training loss 2.912729263305664, test loss 3.3839268628941026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 48594/69826 [4:56:41<12:19:36,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3110016: training loss 2.750831127166748, test loss 3.385501218396564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 48750/69826 [4:57:37<12:11:12,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3120000: training loss 2.9291679859161377, test loss 3.378245891526688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 48907/69826 [4:58:34<12:12:14,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3130048: training loss 2.747238874435425, test loss 3.3902719575305316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 49063/69826 [4:59:30<12:02:32,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3140032: training loss 2.8551366329193115, test loss 3.3945691086525143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 49219/69826 [5:00:27<11:49:30,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3150016: training loss 2.8843932151794434, test loss 3.385501351467399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 49375/69826 [5:01:23<12:02:57,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3160000: training loss 2.7796640396118164, test loss 3.388943367226179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 49532/69826 [5:02:20<11:50:52,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3170048: training loss 2.9520986080169678, test loss 3.3812449976455334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 49688/69826 [5:03:16<11:43:12,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3180032: training loss 2.876492738723755, test loss 3.388726783353229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 49844/69826 [5:04:12<11:25:06,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3190016: training loss 2.7805256843566895, test loss 3.3960324664448582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 50000/69826 [5:05:08<11:21:26,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3200000: training loss 2.732722282409668, test loss 3.3744823932647705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 50157/69826 [5:06:05<11:52:17,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3210048: training loss 2.987197160720825, test loss 3.384582574977431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 50313/69826 [5:07:01<11:10:46,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3220032: training loss 2.9425747394561768, test loss 3.383783124213995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 50469/69826 [5:07:57<11:09:47,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3230016: training loss 2.740058422088623, test loss 3.384966262551241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 50625/69826 [5:08:53<11:02:42,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3240000: training loss 2.7461743354797363, test loss 3.3873930143755535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 50782/69826 [5:09:50<10:59:36,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3250048: training loss 2.749511957168579, test loss 3.3793058617170466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 50938/69826 [5:10:46<10:52:50,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3260032: training loss 2.909900188446045, test loss 3.3820339857145796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 51094/69826 [5:11:43<10:52:36,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3270016: training loss 2.881779909133911, test loss 3.37931657946387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 51250/69826 [5:12:40<10:51:31,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3280000: training loss 2.904838800430298, test loss 3.382968680803166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 51407/69826 [5:13:37<10:39:23,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3290048: training loss 2.82589054107666, test loss 3.375812574874523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 51563/69826 [5:14:33<10:37:18,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3300032: training loss 2.8469552993774414, test loss 3.3692349001418713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 51719/69826 [5:15:30<10:27:55,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3310016: training loss 2.792583703994751, test loss 3.362745484640432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 51875/69826 [5:16:28<10:26:29,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3320000: training loss 2.86140513420105, test loss 3.3715662623560707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 52032/69826 [5:17:25<10:19:38,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3330048: training loss 2.9165866374969482, test loss 3.373233967049177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 52188/69826 [5:18:22<10:13:50,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3340032: training loss 2.8665552139282227, test loss 3.3646945731584417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 52344/69826 [5:19:18<10:17:26,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3350016: training loss 2.7286217212677, test loss 3.3747678080270456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 52500/69826 [5:20:15<10:03:57,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3360000: training loss 2.839590311050415, test loss 3.3727261132972184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 52657/69826 [5:21:13<11:33:10,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3370048: training loss 2.9732985496520996, test loss 3.36448512520901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 52813/69826 [5:22:10<9:58:33,  2.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3380032: training loss 3.123192310333252, test loss 3.36898472142774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 52969/69826 [5:23:07<9:47:54,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3390016: training loss 2.6111581325531006, test loss 3.3719858346983442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 53125/69826 [5:24:04<9:42:02,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3400000: training loss 2.9080018997192383, test loss 3.3667354195616968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 53282/69826 [5:25:01<9:29:35,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3410048: training loss 2.732227087020874, test loss 3.3701903930930204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 53438/69826 [5:25:57<9:28:45,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3420032: training loss 2.9408299922943115, test loss 3.3714842851771865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 53594/69826 [5:26:54<9:19:11,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3430016: training loss 2.9533040523529053, test loss 3.3703310046085093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 53750/69826 [5:27:51<9:30:17,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3440000: training loss 2.741598606109619, test loss 3.3641823557920234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 53907/69826 [5:28:48<9:16:05,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3450048: training loss 2.951082706451416, test loss 3.364413677259933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 54063/69826 [5:29:45<9:21:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3460032: training loss 2.871438503265381, test loss 3.3581390824428823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 54219/69826 [5:30:43<9:45:18,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3470016: training loss 2.725337028503418, test loss 3.370012177977451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 54375/69826 [5:31:39<8:56:47,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3480000: training loss 3.1112306118011475, test loss 3.3564045318337374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 54532/69826 [5:32:36<8:50:38,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3490048: training loss 2.8193962574005127, test loss 3.36283316723136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 54688/69826 [5:33:32<8:47:34,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3500032: training loss 2.86979079246521, test loss 3.3648827685866247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 54844/69826 [5:34:30<8:45:44,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3510016: training loss 2.7271065711975098, test loss 3.362970756929974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 55000/69826 [5:35:27<8:38:53,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3520000: training loss 2.9394383430480957, test loss 3.3691483985546022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 55157/69826 [5:36:23<8:31:39,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3530048: training loss 2.747267007827759, test loss 3.3641868857450263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 55313/69826 [5:37:20<8:33:09,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3540032: training loss 2.897111415863037, test loss 3.3552726923033247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 55469/69826 [5:38:17<8:20:08,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3550016: training loss 2.9709460735321045, test loss 3.355534836303356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 55625/69826 [5:39:14<8:14:21,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3560000: training loss 2.8624138832092285, test loss 3.3549657588781314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 55782/69826 [5:40:11<8:13:52,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3570048: training loss 2.731111764907837, test loss 3.360480230908061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 55938/69826 [5:41:07<8:08:11,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3580032: training loss 2.7962987422943115, test loss 3.3678101938824323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 56094/69826 [5:42:04<8:04:19,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3590016: training loss 2.8520848751068115, test loss 3.359756297843401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 56250/69826 [5:43:01<7:54:57,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3600000: training loss 2.8465492725372314, test loss 3.354952518330064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 56407/69826 [5:43:58<7:55:07,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3610048: training loss 2.9908993244171143, test loss 3.3628810949103776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 56563/69826 [5:44:55<7:39:14,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3620032: training loss 2.693573474884033, test loss 3.3620955666830374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 56719/69826 [5:45:51<7:34:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3630016: training loss 2.617371082305908, test loss 3.3596164071282675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 56875/69826 [5:46:49<7:35:51,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3640000: training loss 2.85888934135437, test loss 3.358954900919005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 57032/69826 [5:47:46<7:20:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3650048: training loss 2.751783847808838, test loss 3.3640237852584485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 57188/69826 [5:48:42<7:21:09,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3660032: training loss 2.8087265491485596, test loss 3.3623559142267982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 57344/69826 [5:49:38<7:12:49,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3670016: training loss 2.8647899627685547, test loss 3.3606015027955523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 57500/69826 [5:50:35<7:09:21,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3680000: training loss 2.9028775691986084, test loss 3.3606458264727923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 57657/69826 [5:51:33<7:06:37,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3690048: training loss 2.7138161659240723, test loss 3.355620683625687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 57813/69826 [5:52:30<7:08:31,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3700032: training loss 2.8337695598602295, test loss 3.349619061447853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 57969/69826 [5:53:27<6:56:39,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3710016: training loss 3.1116271018981934, test loss 3.3521518097367395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 58125/69826 [5:54:25<7:46:30,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3720000: training loss 2.903932809829712, test loss 3.35694219899732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 58282/69826 [5:55:23<6:52:03,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3730048: training loss 3.056936025619507, test loss 3.343012055685354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 58438/69826 [5:56:21<7:15:23,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3740032: training loss 2.8109889030456543, test loss 3.3529183310131696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 58594/69826 [5:57:18<6:41:14,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3750016: training loss 2.8385045528411865, test loss 3.353898336721021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 58750/69826 [5:58:15<6:37:12,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3760000: training loss 2.610107421875, test loss 3.35586422543193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 58907/69826 [5:59:13<6:29:05,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3770048: training loss 2.757756233215332, test loss 3.3598889029303263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 59063/69826 [6:00:10<6:27:22,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3780032: training loss 2.9636712074279785, test loss 3.3583098566809366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 59219/69826 [6:01:07<6:10:32,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3790016: training loss 2.779960870742798, test loss 3.346649358438891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 59375/69826 [6:02:03<6:06:14,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3800000: training loss 3.0324974060058594, test loss 3.3514768966408663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 59532/69826 [6:03:01<6:03:08,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3810048: training loss 2.7981598377227783, test loss 3.352680821751439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 59688/69826 [6:03:57<5:58:54,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3820032: training loss 2.694734811782837, test loss 3.349627505901248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 59844/69826 [6:04:54<5:54:27,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3830016: training loss 2.895301342010498, test loss 3.3464502955591957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 60000/69826 [6:05:51<5:38:58,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3840000: training loss 2.854539394378662, test loss 3.358701694843381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 60157/69826 [6:06:47<5:36:04,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3850048: training loss 2.7620487213134766, test loss 3.3547146763912465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 60313/69826 [6:07:43<5:28:31,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3860032: training loss 2.7887251377105713, test loss 3.3535983008007673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 60469/69826 [6:08:41<6:15:09,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3870016: training loss 2.917811155319214, test loss 3.3478957497796347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 60625/69826 [6:09:38<5:21:17,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3880000: training loss 2.765994071960449, test loss 3.351774049359699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 60782/69826 [6:10:35<5:19:32,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3890048: training loss 2.968693971633911, test loss 3.3505577375722484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 60938/69826 [6:11:33<5:59:02,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3900032: training loss 2.8835816383361816, test loss 3.3488531445347984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 61094/69826 [6:12:30<5:09:33,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3910016: training loss 2.7287769317626953, test loss 3.3443349627561347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 61250/69826 [6:13:26<4:57:04,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3920000: training loss 2.7722067832946777, test loss 3.3504438899284184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 61407/69826 [6:14:24<4:52:47,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3930048: training loss 2.8349761962890625, test loss 3.344358948774116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 61563/69826 [6:15:21<4:43:42,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3940032: training loss 2.5234286785125732, test loss 3.346595758615538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 61719/69826 [6:16:18<4:47:58,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3950016: training loss 2.7760889530181885, test loss 3.349490620369135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 61875/69826 [6:17:14<4:41:58,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3960000: training loss 2.857853412628174, test loss 3.345064562420512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 62032/69826 [6:18:12<4:36:19,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3970048: training loss 2.696380853652954, test loss 3.349789874498234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 62188/69826 [6:19:09<4:31:10,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3980032: training loss 2.7565255165100098, test loss 3.3464343658713407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 62344/69826 [6:20:06<4:24:49,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3990016: training loss 2.8675451278686523, test loss 3.3464283832283908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 62500/69826 [6:21:04<4:40:02,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4000000: training loss 2.6944034099578857, test loss 3.3406928029171254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 62657/69826 [6:22:01<4:13:54,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4010048: training loss 2.7782254219055176, test loss 3.345768850903178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 62813/69826 [6:22:59<4:06:16,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4020032: training loss 2.6471641063690186, test loss 3.344090461730957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 62969/69826 [6:23:56<4:03:24,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4030016: training loss 2.88830304145813, test loss 3.3472126750058906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 63125/69826 [6:24:53<3:54:22,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4040000: training loss 2.8180391788482666, test loss 3.352896429771601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 63282/69826 [6:25:51<3:53:35,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4050048: training loss 2.9288315773010254, test loss 3.348329089408697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 63438/69826 [6:26:48<3:44:24,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4060032: training loss 2.826979160308838, test loss 3.3468838514283648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 63594/69826 [6:27:45<3:41:55,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4070016: training loss 2.72946834564209, test loss 3.339722228604694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 63750/69826 [6:28:42<3:35:10,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4080000: training loss 2.804208755493164, test loss 3.341210648070934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 63907/69826 [6:29:40<3:29:31,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4090048: training loss 2.8489866256713867, test loss 3.3426478851673216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 64063/69826 [6:30:37<3:23:07,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4100032: training loss 2.8831446170806885, test loss 3.3382704812426898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 64219/69826 [6:31:34<3:17:25,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4110016: training loss 2.6763429641723633, test loss 3.3477390422377478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 64375/69826 [6:32:31<3:12:59,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4120000: training loss 2.6860294342041016, test loss 3.344155134156693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 64532/69826 [6:33:28<3:05:46,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4130048: training loss 2.7003824710845947, test loss 3.3349866201711253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 64688/69826 [6:34:25<2:59:27,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4140032: training loss 2.8819448947906494, test loss 3.3441853578700576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 64844/69826 [6:35:22<2:55:22,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4150016: training loss 2.817657947540283, test loss 3.3410263006077257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 65000/69826 [6:36:19<2:51:29,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4160000: training loss 2.5997602939605713, test loss 3.33433375802151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 65157/69826 [6:37:17<2:43:24,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4170048: training loss 2.6769251823425293, test loss 3.3456264096637103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 65313/69826 [6:38:14<2:40:17,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4180032: training loss 2.5965025424957275, test loss 3.3423721069513364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 65469/69826 [6:39:11<2:35:30,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4190016: training loss 3.0582432746887207, test loss 3.3408577109492104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 65625/69826 [6:40:08<2:27:28,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4200000: training loss 2.8161473274230957, test loss 3.3367251462714616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 65782/69826 [6:41:06<2:23:15,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4210048: training loss 2.768052816390991, test loss 3.3380187888478123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 66094/69826 [6:43:01<2:11:53,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4230016: training loss 2.793997287750244, test loss 3.3363552703413855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 66250/69826 [6:43:57<2:06:59,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4240000: training loss 2.746814012527466, test loss 3.3347704355106798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 66407/69826 [6:44:56<2:15:46,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4250048: training loss 2.8083605766296387, test loss 3.341709253399871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 66563/69826 [6:45:55<2:10:09,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4260032: training loss 2.618964910507202, test loss 3.3352863289589108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 66719/69826 [6:46:53<1:57:38,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4270016: training loss 2.8803465366363525, test loss 3.3343670534533123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 66875/69826 [6:47:49<1:44:36,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4280000: training loss 2.89188551902771, test loss 3.3365788681562556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 67032/69826 [6:48:47<1:39:26,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4290048: training loss 2.8078064918518066, test loss 3.328180379645769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 67188/69826 [6:49:44<1:33:30,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4300032: training loss 2.5658609867095947, test loss 3.3335308751394583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 67344/69826 [6:50:41<1:28:27,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4310016: training loss 2.6987357139587402, test loss 3.3323054036428763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 67500/69826 [6:51:38<1:22:31,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4320000: training loss 2.9942026138305664, test loss 3.3338621383489566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 67657/69826 [6:52:35<1:16:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4330048: training loss 2.77812123298645, test loss 3.337223585261855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 67813/69826 [6:53:32<1:11:49,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4340032: training loss 2.6995036602020264, test loss 3.33186591503232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 67969/69826 [6:54:29<1:05:51,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4350016: training loss 2.5653281211853027, test loss 3.3337945217309994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 68125/69826 [6:55:26<1:00:47,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4360000: training loss 2.868601083755493, test loss 3.3314333128374676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 68282/69826 [6:56:23<54:40,  2.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4370048: training loss 2.72270131111145, test loss 3.3277151196501977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 68438/69826 [6:57:20<49:14,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4380032: training loss 2.608931541442871, test loss 3.3345756364423176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 68594/69826 [6:58:17<43:37,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4390016: training loss 3.057827949523926, test loss 3.3252931971882664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 68750/69826 [6:59:15<38:08,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4400000: training loss 2.7265071868896484, test loss 3.327544611553813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 68907/69826 [7:00:12<32:46,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4410048: training loss 2.8935868740081787, test loss 3.330546024233796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 68987/69826 [7:00:38<04:30,  3.10it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key = 'rpe_konly_perlayer_skew_n8_h8_d512_c64_v2'\n",
    "model = model_krpe_perlayer_skew\n",
    "\n",
    "_ = model.apply(train_utils.min_gpt_init_weights)\n",
    "train_utils.train_epoch(\n",
    "    model,\n",
    "    loss_histories,\n",
    "    key,\n",
    "    'cuda',\n",
    "    train_loader_autoreg,\n",
    "    test_loader_autoreg,\n",
    "    dataset_config,\n",
    "    save_every=float('inf'),\n",
    "    eval_every=10000,\n",
    "    save_state_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b39cbdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saved_models/loss_histories.pickle', 'wb') as f:\n",
    "    pickle.dump(loss_histories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f11a5",
   "metadata": {},
   "source": [
    "## Analysis + Conclusions\n",
    "\n",
    "We expect to see no difference in training curves between the \"fast\" skew version and the original shaw et al 2018 version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44024d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(arr, window):\n",
    "    runsum = sum(arr[:window])\n",
    "    out = [runsum / window]\n",
    "    i = 0\n",
    "    j = window\n",
    "    \n",
    "    while j < len(arr):\n",
    "        runsum -= arr[i]\n",
    "        runsum += arr[j]\n",
    "        out.append(runsum/window)\n",
    "        i += 1\n",
    "        j += 1\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fcd40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(xy_pairs, smooth_window=0, **kwargs):\n",
    "    examples, loss = zip(*xy_pairs)\n",
    "    if smooth_window > 0:\n",
    "        loss = smooth(loss, smooth_window)\n",
    "        examples = examples[:len(loss)]\n",
    "    plt.plot(examples, loss, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e67bd09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.7, 3.6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "window = 1000\n",
    "plot_loss(loss_histories['rpe_konly_perlayer_n8_h8_d512_c64']['train_loss'],\n",
    "          smooth_window=window,\n",
    "          color='blue',\n",
    "          linestyle=':',\n",
    "          linewidth=2)\n",
    "plot_loss(loss_histories['rpe_konly_perlayer_skew_n8_h8_d512_c64_v2']['train_loss'],\n",
    "          smooth_window=window,\n",
    "          color='orange',\n",
    "          linestyle=':',\n",
    "          linewidth=2)\n",
    "plt.title('Smoothed train loss')\n",
    "plt.legend([\n",
    "    'Key-only RPE per-layer',\n",
    "    'Key-only RPE per-layer with skew',\n",
    "])\n",
    "plt.ylim([2.7, 3.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f64b6aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd9f3899fd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plot_loss(loss_histories['rpe_konly_perlayer_n8_h8_d512_c64']['test_loss'],\n",
    "          color='blue',\n",
    "          linestyle=':',\n",
    "          linewidth=2)\n",
    "plot_loss(loss_histories['rpe_konly_perlayer_skew_n8_h8_d512_c64_v2']['test_loss'],\n",
    "          color='orange',\n",
    "          linestyle=':',\n",
    "          linewidth=2)\n",
    "plt.title('Test loss')\n",
    "plt.legend([\n",
    "    'Key-only RPE per-layer',\n",
    "    'Key-only RPE per-layer with skew',\n",
    "])\n",
    "#plt.ylim([3.3, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
